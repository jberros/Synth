# -*- coding: utf-8 -*-
"""Synth_baseline_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DR3VqDG_fyxUUDHlKkHd6FFlaRlbqtFQ

# Introduction

Synth (Subnet 50) redefines how synthetic financial data is modelled and utilized for predictive intelligence.

Powered by Bittensorâ€™s decentralized intelligence network, Synth replaces the traditional, opaque data models with an open, verifiable, and continuously evolving synthetic data layer where the models compete, refine, and enhance monte-carlo simulations of price forecasts to unprecedented levels.

- [Visit their website](https://www.synthdata.co/)
- [Read more in the whitepaper](https://mode-network.github.io/synth-subnet/Synth%20Whitepaper%20v1.pdf)

# Setup

The first steps to get started are:
1. Install the [package dedicated to this competition](https://github.com/crunchdao/synth-crunch)
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install synth-crunch

"""# Your model

## Setup
"""

from synth_crunch.baseline import convert_prices_to_time_format
from synth_crunch import pyth
import numpy as np
from datetime import datetime, timedelta
from typing import Any
from scipy.stats import t, norm
from scipy.optimize import minimize

# Import the synth classes
from synth_crunch import Asset, SynthMiner

"""## Implementation

### `SynthMiner.generate_simulations()`

You must implement a class with the mandatory function, generate_simulations().

This function will be called each time the protocol asks your model to make predictions.

You must predict the possible paths (called simulations), of an `asset` at regular intervals (`time_increment`), for a determined amount of time (`time_length`).
"""

class MyMiner(SynthMiner):

    def __init__(self):
        pass

    def generate_simulations(
        self,
        asset: Asset,  # can only be "BTC", "ETH", "XAU" or "SOL"
        current_price: float,
        start_time: str,
        time_increment: int,
        time_length: int,
        num_simulations: int,
    ) -> list[list[dict[str, Any]]]:
        """
        Generate simulated price paths.

        Parameters:
            asset (str): The asset to simulate.
            current_price (float): The current price of the asset to simulate.
            start_time (str): The start time of the simulation.
            time_increment (int): Time increment in seconds (e.g., 60 for 1min, 300 for 5min).
            time_length (int): Total time length in seconds (e.g., 300 for 5min, 86400 for 24h).
            num_simulations (int): Number of simulation runs (typically 100).

        Returns:
            list[list[dict[str, Any]]]: Simulated price paths in time format.
        """
        if not start_time:
            start_time = datetime.now().isoformat()

        # Adjust history based on test type
        days = 7 if time_increment <= 60 else 10  # 10 days for historical

        # Try resolutions in order
        resolutions = ["minute", "2minute", "5minute"] if time_increment <= 60 else ["2minute", "5minute"]
        past_prices = None
        res_seconds = None
        for res in resolutions:
            try:
                past_prices = pyth.get_price_history(
                    asset=asset,
                    from_=datetime.fromisoformat(start_time) - timedelta(days=days),
                    to=datetime.fromisoformat(start_time),
                    resolution=res,
                ).tolist()
                res_seconds = {"minute": 60, "2minute": 120, "5minute": 300}[res]
                break
            except Exception as e:
                if "Too many datapoints" not in str(e) or res == resolutions[-1]:
                    raise

        # Parameter estimation
        if len(past_prices) < 100:
            mu = 0.0
            sigma = 0.01
            initial_vol = sigma
            garch_params = None
        else:
            log_prices = np.log(past_prices)
            returns = np.diff(log_prices)
            mu = 0.0

            # GARCH(1,1) fit
            garch_params, initial_vol = self.fit_garch(returns, asset)
            if garch_params is None:
                # Fallback to EWMA
                def get_ewma_vol(rets, alpha=0.94):
                    if len(rets) == 0:
                        return 0.01
                    sq_rets = rets ** 2
                    var_ew = np.zeros_like(sq_rets)
                    var_ew[0] = sq_rets[0]
                    for i in range(1, len(sq_rets)):
                        var_ew[i] = alpha * var_ew[i - 1] + (1 - alpha) * sq_rets[i]
                    return np.sqrt(var_ew[-1])
                sigma = get_ewma_vol(returns)
                initial_vol = sigma
            else:
                # Scale to step size
                scale_factor = np.sqrt(time_increment / res_seconds)
                initial_vol *= scale_factor

            # Asset-specific scaling
            multipliers = {"BTC": 3.0, "ETH": 1.25, "XAU": 0.5, "SOL": 0.75}
            initial_vol *= multipliers.get(asset, 1.0)

        num_steps = time_length // time_increment
        simulations = self.simulate_crypto_price_paths(
            current_price=current_price,
            mu=mu,
            initial_vol=initial_vol,
            garch_params=garch_params,
            step_minutes=time_increment / 60,
            res_seconds=res_seconds,
            num_steps=num_steps,
            num_simulations=num_simulations,
        )

        predictions = convert_prices_to_time_format(
            prices=simulations.tolist(),
            start_time=start_time,
            time_increment=time_increment,
        )

        return predictions

    def fit_garch(self, returns, asset):
        """
        Fit GARCH(1,1) parameters using MLE.
        Returns (omega, alpha, beta), initial_vol or None if fails.
        """
        n = len(returns)
        if n < 100:
            return None, np.std(returns)

        def neg_log_lik(params):
            omega, alpha, beta = np.exp(params)
            if alpha + beta >= 1:
                return np.inf
            vol_sq = np.zeros(n + 1)
            vol_sq[0] = np.var(returns)
            for t in range(1, n + 1):
                vol_sq[t] = omega + alpha * returns[t - 1] ** 2 + beta * vol_sq[t - 1]
            vol = np.sqrt(vol_sq[1:])
            lik = -0.5 * (np.log(2 * np.pi) + 2 * np.log(vol) + (returns ** 2) / vol_sq[1:])
            return -np.sum(lik)

        # Asset-specific start params (BTC-tuned)
        start_params = np.log([np.var(returns) / 252, 0.1 if asset == "BTC" else 0.05, 0.9])
        bounds = [(np.log(1e-6), np.log(1e2)), (np.log(1e-8), np.log(0.3)), (np.log(1e-8), np.log(0.95))]
        res = minimize(neg_log_lik, start_params, method='L-BFGS-B', bounds=bounds)

        if res.success:
            omega, alpha, beta = np.exp(res.x)
            vol_sq = np.zeros(n + 1)
            vol_sq[0] = np.var(returns)
            for t in range(1, n + 1):
                vol_sq[t] = omega + alpha * returns[t - 1] ** 2 + beta * vol_sq[t - 1]
            initial_vol = np.sqrt(vol_sq[-1])
            return (omega, alpha, beta), initial_vol
        else:
            return None, np.std(returns)

    def simulate_single_price_path(
        self,
        current_price: float,
        mu: float,
        initial_vol: float,
        garch_params: tuple,
        step_minutes: float,
        res_seconds: float,
        num_steps: int,
    ):
        """
        Simulate a single path with GARCH conditional vol and normal mixture shocks.
        """
        df = 2.5  # Heavy tails
        price_path = np.zeros(num_steps + 1)
        price_path[0] = current_price

        if garch_params is None:
            loc = mu - 0.5 * initial_vol ** 2
            scale_t = initial_vol * np.sqrt((df - 2) / df)
            # Normal mixture: 90% main, 10% tail (negative shift, higher var)
            choices = np.random.choice([0, 1], size=num_steps, p=[0.9, 0.1])
            shocks = np.zeros(num_steps)
            for i in range(num_steps):
                if choices[i] == 0:
                    shocks[i] = norm.rvs(loc=loc, scale=scale_t)
                else:
                    shocks[i] = norm.rvs(loc=loc - 0.5 * scale_t, scale=2 * scale_t)
            for i in range(1, num_steps + 1):
                price_path[i] = price_path[i - 1] * np.exp(shocks[i - 1])
            return price_path

        omega, alpha, beta = garch_params
        scale_factor = np.sqrt(step_minutes / (res_seconds / 60))
        vol_t = initial_vol  # Already scaled
        omega_step = omega * (step_minutes / (res_seconds / 60))
        for i in range(1, num_steps + 1):
            loc = mu - 0.5 * vol_t ** 2
            scale = vol_t
            scale_t = scale * np.sqrt((df - 2) / df)
            # Normal mixture
            choice = np.random.choice([0, 1], p=[0.9, 0.1])
            shock = norm.rvs(loc=loc, scale=scale_t) if choice == 0 else norm.rvs(loc=loc - 0.5 * scale_t, scale=2 * scale_t)
            price_path[i] = price_path[i - 1] * np.exp(shock)
            vol_t = np.sqrt(omega_step + alpha * shock ** 2 + beta * vol_t ** 2)

        return price_path

    def simulate_crypto_price_paths(
        self,
        current_price: float,
        mu: float,
        initial_vol: float,
        garch_params: tuple,
        step_minutes: float,
        res_seconds: float,
        num_steps: int,
        num_simulations: int,
    ):
        """
        Simulate multiple crypto asset price paths.
        """
        price_paths = []
        for _ in range(num_simulations):
            price_path = self.simulate_single_price_path(
                current_price,
                mu,
                initial_vol,
                garch_params,
                step_minutes,
                res_seconds,
                num_steps,
            )
            price_paths.append(price_path)

        return np.array(price_paths)

"""## Local testing

### Using historical data

We recommend using historical data for quick iterations because you can be scored immediately.

Once you have generated your simulations, they are validated to ensure that you are ready for the network.
"""

from synth_crunch import test_historical, score_simulations
from datetime import datetime

result = test_historical(
    MyMiner(),
    "BTC",
    start=datetime(2024, 2, 1, 14),
    time_increment=300,
    time_length=86400,
    num_simulations=100,
)

scored_result = score_simulations(result)
print("My miner score is:", scored_result.score)
print("\nMore details:")
print(scored_result.score_summary)

# V1 miner score is: 4700.9032693127615
# V2 miner score is: 3290.9032693127615

# More details:
#   Interval        CRPS
#       5min 1867.517008
#      30min  894.037360
#      3hour  377.288951
# 24hour_abs  152.059950
#    Overall 3290.903269

"""#### Visualize your simulations

The utility provides a quick way to visualize your simulations.

To clearly see the different paths, we suggest keeping the number of simulations low.
"""

# Import the function
from synth_crunch import visualize_simulations

visualize_simulations(
    result,
)

"""#### Score your simulations

Your simulations will be scored using [Synth Subnet's scoring function](https://github.com/mode-network/synth-subnet/blob/d076dc3bcdf93256a278dfec1cbe72b0c47612f6/synth/validator/crps_calculation.py#L5).

### Using live data

Once you're ready, you can run your miner against live data.

However, the longer your `time_length` is, the longer you will have to wait to score your simulations.
"""

from synth_crunch import test_live
result = test_live(
    MyMiner(),
    "BTC",
    time_increment=60,
    time_length=300,
    num_simulations=100,
)

"""#### Visualize your simulations

You can also visualize the different paths generated by your miner. The only difference is that there are no lines for the actual price.
"""

# Import the function
from synth_crunch import visualize_simulations

visualize_simulations(
    result,
    show_past=2,
)

# Import the function
from synth_crunch import score_simulations

# Score your results
scored_result = score_simulations(
    result,
)

print("My miner score is:", scored_result.score)
print()

print("More details:")
print(scored_result.score_summary)

# V1 My miner score is: 25.49501197330226
# V2 My miner score is: 10.37626547294084

# More details:
#   Interval        CRPS
#       5min    5.177572
# 24hour_abs    5.198694
#    Overall   10.376265

### Querying more historical data

To meet your training needs, you can query the historical data provided by [Pyth](https://www.pyth.network/).
"""

# Import the function
from synth_crunch import pyth

prices = pyth.get_price_history(
    # Specify which asset you want to get data of: "BTC," "ETH," "XAU," or "SOL".
    asset="BTC",

    # Start time of the data
    from_=datetime(2024, 1, 1),

    # End time of the data
    to=datetime(2024, 6, 1),

    # Resolution of the data, can be "minute", "2minute", "5minute", "15minute", "30minute", "hour", "2hour", "4hour", "6hour", "12hour", "day", "week" or "month".
    resolution="30minute",
)

prices

"""# Submit your Notebook

To submit your work, you must:
1. Download your Notebook from Colab
2. Upload it to the platform
3. Create a run to validate it

### >> https://hub.crunchdao.io/competitions/synth/submit/notebook
"""
